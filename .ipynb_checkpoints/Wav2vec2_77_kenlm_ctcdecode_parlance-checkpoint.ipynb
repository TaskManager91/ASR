{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e545d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kenlm\n",
    "import ctcdecode\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_from_disk, load_dataset, load_metric, Dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07e30e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "labels = ['o', 'm', '\\u00f6', 'v', 'p', 'y', 'z', 'f', 'd', 'j', 'i', 't', 'r', '\\u00e4', 'n', 'w', 'h', 'l', 'u', 'a', 'x', 's', 'b', 'c', '\\u00df', '\\u00fc', 'e', 'g', 'q', ' ', 'k', '_', '_']\n",
    "\n",
    "decoder = CTCBeamDecoder(\n",
    "    labels,\n",
    "    model_path='lm_data/train_utf.arpa',\n",
    "    alpha=0.5,\n",
    "    beta=0,\n",
    "    cutoff_top_n=40,\n",
    "    cutoff_prob=np.log(0.000001),\n",
    "    beam_width=128,\n",
    "    num_processes=2,\n",
    "    blank_id=32,\n",
    "    log_probs_input=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3ec25fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "#labels = ['o', 'm', '\\u00f6', 'v', 'p', 'y', 'z', 'f', 'd', 'j', 'i', 't', 'r', '\\u00e4', 'n', 'w', 'h', 'l', 'u', 'a', 'x', 's', 'b', 'c', '\\u00df', '\\u00fc', 'e', 'g', 'q', ' ', 'k', '_', '_']\n",
    "\n",
    "vocab = ['o', 'm', 'ö', 'v', 'p', 'y', 'z', 'f', 'd', 'j', 'i', 't', 'r', 'ä', 'n', 'w', 'h', 'l', 'u', 'a', 'x', 's', 'b', 'c', 'ß', 'ü', 'e', 'g', 'q', ' ', 'k', '_', '_']\n",
    "\n",
    "\n",
    "decoder = CTCBeamDecoder(\n",
    "    labels,\n",
    "    model_path=None,\n",
    "    alpha=0.5,\n",
    "    beta=0,\n",
    "    cutoff_top_n=40,\n",
    "    cutoff_prob=np.log(0.000001),\n",
    "    beam_width=128,\n",
    "    num_processes=2,\n",
    "    blank_id=32,\n",
    "    log_probs_input=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7eff62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_decoder = CTCBeamDecoder(\n",
    "    labels,\n",
    "    model_path='lm_data/train_utf.arpa',\n",
    "    alpha=0.5,\n",
    "    beta=0,\n",
    "    cutoff_top_n=100,\n",
    "    cutoff_prob=np.log(0.0000001),\n",
    "    beam_width=256,\n",
    "    num_processes=2,\n",
    "    blank_id=32,\n",
    "    log_probs_input=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "663bccac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "f = open(\"lm_data/train.arpa\", \"r\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "content= f.read()\n",
    "f.close()\n",
    "\n",
    "f= open(\"lm_data/train_utf.arpa\", 'w', encoding=\"utf-8\")\n",
    "f.write(content)\n",
    "f.close()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c01d1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_51_full_log_2 = load_from_disk(\"lm_res51/res51_full_log_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90b5e14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_51_full_full = load_from_disk(\"lm_full_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "428e51fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Prd:  zieht euch bitte draußen die schuhe aus\n",
      "Tar:  zieht euch bitte draußen die schuhe aus \n",
      "Old:  zieht euch bitte draußen die schuhe aus \n",
      "New:  zieht euch bitte draußen die schuhe aus \n",
      "1\n",
      "Prd:  des komtikolnegabentert\n",
      "Tar:  es kommt zum showdown in gstaad \n",
      "Old:  des kontingentes \n",
      "New:  das kontingente \n",
      "2\n",
      "Prd:  ihre fortestrecken erschienen mit molemagazine wie der wog at das basarwaryclar\n",
      "Tar:  ihre fotostrecken erschienen in modemagazinen wie der vogue harpers bazaar und marie claire \n",
      "Old:  ihre forte strecken erschienen mit modemagazin wie der vogtes basar barrique \n",
      "New:  ihre fotostrecken erschienen mit modemagazin wie der vogtes basilique \n",
      "3\n",
      "Prd:  verlibert eine auch für monachen ungewöhnlich lange titelliste\n",
      "Tar:  felipe hat eine auch für monarchen ungewöhnlich lange titelliste \n",
      "Old:  verliert eine auch für monarchen ungewöhnlich lange titelliste \n",
      "New:  verliert eine auch für monarchen ungewöhnlich lange titelliste \n",
      "4\n",
      "Prd:  er wurde zu ehren des reichskanzlers otto von bismark errichtet\n",
      "Tar:  er wurde zu ehren des reichskanzlers otto von bismarck errichtet \n",
      "Old:  er wurde zu ehren des reichskanzler otto von bismarck errichtet \n",
      "New:  er wurde zu ehren des reichskanzler otto von bismarck errichtet \n",
      "5\n",
      "Prd:  was solls ich bin bereit\n",
      "Tar:  was solls ich bin bereit \n",
      "Old:  was solls ich bin bereit \n",
      "New:  was solls ich bin bereit \n",
      "6\n",
      "Prd:  das internet besteht aus vielen computern die miteinander verbunden sind\n",
      "Tar:  das internet besteht aus vielen computern die miteinander verbunden sind \n",
      "Old:  das internet besteht aus vielen computern die miteinander verbunden sind \n",
      "New:  das internet besteht aus vielen computern die miteinander verbunden sind \n",
      "7\n",
      "Prd:  der uranus ist eir siebente planet en u unsermsammensystem\n",
      "Tar:  der uranus ist der siebente planet in unserem sonnensystem \n",
      "Old:  der uranus ist der siebente planeten unser sammelsystem \n",
      "New:  der uranus ist der siebente planeten unser sonnensystem \n",
      "8\n",
      "Prd:  die wagen erhielten ein einheitliches erscheinungsbild in weis mit rotem fensterband\n",
      "Tar:  die wagen erhielten ein einheitliches erscheinungsbild in weiß mit rotem fensterband \n",
      "Old:  die wagen erhielten ein einheitliches erscheinungsbild in weis mit rotem fensterband \n",
      "New:  die wagen erhielten ein einheitliches erscheinungsbild in weiß mit rotem fensterband \n",
      "9\n",
      "Prd:  sie war die cousinefin karlmaria vin weber\n",
      "Tar:  sie war die cousine von carl maria von weber \n",
      "Old:  sie war die cousine von karlmaria von weber \n",
      "New:  sie war die cousine von carlmariavonweber\n",
      "10\n",
      "Prd:  seinen vornamen erhielt er in gedenken an seinen früh verstorbenen onkel\n",
      "Tar:  seinen vornamen erhielt er in gedenken an seinen früh verstorbenen onkel \n",
      "Old:  sein vornamen erhielt er in gedenken an seinen früh verstorbenen onkel \n",
      "New:  sein vornamen erhielt er in gedenken an seinen früh verstorbenen onkel \n",
      "11\n",
      "Prd:  vorher udanach wurde er lebe im rapen\n",
      "Tar:  vorher und danach war der löwe im wappen \n",
      "Old:  vorher danach wurde er lebe im wappen \n",
      "New:  vorher danach wurde er lebe im wappen \n",
      "12\n",
      "Prd:  insgesamt ist der sound etwas zu bassloistig\n",
      "Tar:  insgesamt ist der sound etwas zu basslastig \n",
      "Old:  insgesamt ist der sound etwas zu bass lustig \n",
      "New:  insgesamt ist der sound etwas zu basslastig\n",
      "13\n",
      "Prd:  wie ist die derzeitige verkehrssituation\n",
      "Tar:  wie ist die derzeitige verkehrssituation \n",
      "Old:  wie ist die derzeitige verkehrssituation \n",
      "New:  wie ist die derzeitige verkehrssituation \n",
      "14\n",
      "Prd:  die schmaz wird cin scholl angegeben\n",
      "Tar:  dieses maß wird in zoll angegeben \n",
      "Old:  die schmalz wird in scholl angegeben \n",
      "New:  die schmalz wird in scholl angegeben \n",
      "15\n",
      "Prd:  ein großer teil der grenciergerie wird heute für die barisergerichte genutzt\n",
      "Tar:  ein großer teil der conciergerie wird heute für die pariser gerichte genutzt \n",
      "Old:  ein großer teil der grenier erie wird heute für die pariser gerichte genutzt \n",
      "New:  ein großer teil der raserei wird heute für die pariser gerichte genutzt \n",
      "16\n",
      "Prd:  weshalb möchtest du nach berg heim\n",
      "Tar:  weshalb möchtest du nach bergheim \n",
      "Old:  weshalb möchtest du nach bergheim \n",
      "New:  weshalb möchtest du nach bergheim \n",
      "17\n",
      "Prd:  aufflage des wettbewerbes\n",
      "Tar:  auflage des wettbewerbes \n",
      "Old:  auflage des wettbewerbs \n",
      "New:  auflage des wettbewerbs \n",
      "18\n",
      "Prd:  seit ihrem achten lebensjahr bekam sie tanzunterricht\n",
      "Tar:  seit ihrem achten lebensjahr bekam sie tanzunterricht \n",
      "Old:  seit ihrem achten lebensjahr bekam sie tanzunterricht \n",
      "New:  seit ihrem achten lebensjahr bekam sie tanzunterricht \n",
      "19\n",
      "Prd:  wir müssen zwei dinge ganz klar unterscheiden\n",
      "Tar:  wir müssen zwei dinge ganz klar unterscheiden \n",
      "Old:  wir müssen zwei dinge ganz klar unterscheiden \n",
      "New:  wir müssen zwei dinge ganz klar unterscheiden \n"
     ]
    }
   ],
   "source": [
    "#vocab_dict = {\"o\": 0, \"m\": 1, \"\\u00f6\": 2, \"v\": 3, \"p\": 4, \"y\": 5, \"z\": 6, \"f\": 7, \"d\": 8, \"j\": 9, \"i\": 10, \"t\": 11, \"r\": 12, \"\\u00e4\": 13, \"n\": 14, \"w\": 15, \"h\": 16, \"l\": 17, \"u\": 18, \"a\": 19, \"x\": 20, \"s\": 21, \"b\": 22, \"c\": 23, \"\\u00df\": 24, \"\\u00fc\": 25, \"e\": 26, \"g\": 27, \"q\": 28, \"k\": 30, \" \": 29, \"[UNK]\": 31, \"[PAD]\": 32}\n",
    "\n",
    "vocab_dict = {'o': 0, 'm': 1, 'ö': 2, 'v': 3, 'p': 4, 'y': 5, 'z': 6, 'f': 7, 'd': 8, 'j': 9, 'i': 10, 't': 11, 'r': 12, 'ä': 13, 'n': 14, 'w': 15, 'h': 16, 'l': 17, 'u': 18, 'a': 19, 'x': 20, 's': 21, 'b': 22, 'c': 23, 'ß': 24, 'ü': 25, 'e': 26, 'g': 27, 'q': 28, 'k': 30, ' ': 29, '[UNK]': 31, '[PAD]': 32}\n",
    "inv_map = {v: k for k, v in vocab_dict.items()}\n",
    "\n",
    "for i in range(20):\n",
    "    logs = res_51_full_log_2[i][\"lm_raw_2\"]\n",
    "    beam_results, beam_scores, timesteps, out_len = lm_decoder.decode(torch.tensor(logs))\n",
    "\n",
    "    res = \"\"\n",
    "    for n in beam_results[0][0][:out_len[0][0]]:\n",
    "        res = res + inv_map[int(n)]\n",
    "\n",
    "    pred_text = res_51_full_log_2[i]['pred_str']\n",
    "    tar_text = res_51_full_log_2[i]['target_text']\n",
    "    old_lm = res_51_full_full[i]['lm_str']\n",
    "    print(i)\n",
    "    print(\"Prd: \",pred_text)\n",
    "    print(\"Tar: \",tar_text)\n",
    "    print(\"Old: \",old_lm)\n",
    "    print(\"New: \",res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa35e303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_lm(batch):\n",
    "    beam_results, beam_scores, timesteps, out_len = decoder.decode(torch.tensor(batch[\"lm_raw_2\"]))\n",
    "    res = \"\"\n",
    "    for n in beam_results[0][0][:out_len[0][0]]:\n",
    "        res = res + inv_map[int(n)]\n",
    "        \n",
    "    batch[\"lm_2_str\"] = res\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96702324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function infer_lm at 0x7f0488796700> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Parameter 'function'=<function infer_lm at 0x7f0488796790> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Parameter 'function'=<function infer_lm at 0x7f0488796700> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Parameter 'function'=<function infer_lm at 0x7f0488796700> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Parameter 'function'=<function infer_lm at 0x7f0488796700> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Parameter 'function'=<function infer_lm at 0x7f0488796790> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a847e12e561741c58b5cc646085eb3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #0', max=1949.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function infer_lm at 0x7f0488796700> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Parameter 'function'=<function infer_lm at 0x7f0488796700> of the transform datasets.arrow_dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a1fdc29945473790f454691d799ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #1', max=1949.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d71c7aafc946d491231bca3f091ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #5', max=1948.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ecb2ccdc33465996081d060216da08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #2', max=1949.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134e13dfb5e422287033f780f4121a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #4', max=1948.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ac6a0df5fd499dbc3e0c90b5815eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #3', max=1949.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ed75b6af9d45d5877a29f03dd33660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #7', max=1948.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a7c646149c45369f49d3ef62ede279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description=' #6', max=1948.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_51_full_log_2 = res_51_full_log_2.map(infer_lm, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e31e5fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Test WER: 0.147\n"
     ]
    }
   ],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "print(\"Full Test WER: {:.3f}\".format(wer_metric.compute(predictions=res_51_full_log_2[\"pred_str\"], references=res_51_full_log_2[\"target_text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8773851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Test WER: 0.129\n"
     ]
    }
   ],
   "source": [
    "print(\"Full Test WER: {:.3f}\".format(wer_metric.compute(predictions=res_51_full_log_2[\"lm_2_str\"], references=res_51_full_log_2[\"target_text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbee7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
