{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kenlm\n",
    "import ctcdecode\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor\n",
    "\n",
    "from datasets import load_from_disk, load_dataset, load_metric, Dataset, concatenate_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"./wav2vec2-large-xlsr-ger-chris/checkpoint-51000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = tokenizer.get_vocab()\n",
    "sort_vocab = sorted((value, key) for (key,value) in vocab_dict.items())\n",
    "vocab = [x[1].replace(\"|\", \" \") if x[1] not in tokenizer.all_special_tokens else \"_\" for x in sort_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1gram\n",
      "found 2gram\n"
     ]
    }
   ],
   "source": [
    "alpha = 2.5 # LM Weight\n",
    "beta = 0.0 # LM Usage Reward\n",
    "word_lm_scorer = ctcdecode.WordKenLMScorer('lm_data/train.arpa', alpha, beta) # use your own kenlm model\n",
    "\n",
    "decoder = ctcdecode.BeamSearchDecoder(\n",
    "    vocab,\n",
    "    num_workers=2,\n",
    "    beam_width=128,\n",
    "    scorers=[word_lm_scorer],\n",
    "    cutoff_prob=np.log(0.000001),\n",
    "    cutoff_top_n=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res51_full_log = load_from_disk(\"res51_full_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampled = load_from_disk(\"/media/chris/TheFlash/Master/data/test_sampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_lm(batch, word_lm_scorer, vocabulary):\n",
    "    from ctcdecode.prefix import State\n",
    "    import numpy as np\n",
    "\n",
    "    def get_pruned_vocab_indices(log_probs):\n",
    "        \"\"\" Return vocab indices of pruned probabilities of a time step. \"\"\"\n",
    "\n",
    "        index_to_prob = [(k, log_probs[k]) for k in range(log_probs.shape[0])]\n",
    "        index_to_prob = sorted(index_to_prob, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if 40 < len(index_to_prob):\n",
    "            index_to_prob = index_to_prob[:40]\n",
    "\n",
    "        if np.log(0.000001) < 1.0:\n",
    "            filtered = []\n",
    "            for x in index_to_prob:\n",
    "                if x[1] >= np.log(0.000001):\n",
    "                    filtered.append(x)\n",
    "            index_to_prob = filtered\n",
    "\n",
    "        return [x[0] for x in index_to_prob]\n",
    "\n",
    "    def decode(probs):\n",
    "        # Num time steps\n",
    "        nT = probs.shape[0]\n",
    "\n",
    "        # Initialize prefixes\n",
    "        prefixes = State(\n",
    "            scorers=[word_lm_scorer],\n",
    "            size=128\n",
    "        )\n",
    "\n",
    "        # Iterate over timesteps\n",
    "        for t in range(nT):\n",
    "            step_probs = probs[t]\n",
    "            pruned_step_probs = get_pruned_vocab_indices(step_probs)\n",
    "\n",
    "            # Iterate over symbols\n",
    "            for v in pruned_step_probs:\n",
    "                symbol = vocabulary[v]\n",
    "                symbol_prob = step_probs[v]\n",
    "\n",
    "                # Iterate over prefixes\n",
    "                for prefix in prefixes:\n",
    "\n",
    "                    # If there is a blank, we extend the existing prefix\n",
    "                    if symbol == '_':\n",
    "                        prefix.add_p_blank(symbol_prob + prefix.score)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # If the last symbol is repeated\n",
    "                        # update the existing prefix\n",
    "                        if symbol == prefix.symbol:\n",
    "                            p = symbol_prob + prefix.p_non_blank_prev\n",
    "                            prefix.add_p_non_blank(p)\n",
    "\n",
    "                        new_prefix = prefixes.get_prefix(prefix, symbol)\n",
    "\n",
    "                        if new_prefix is not None:\n",
    "                            p = -np.inf\n",
    "\n",
    "                            if symbol == prefix.symbol and \\\n",
    "                                    prefix.p_blank_prev > -np.inf:\n",
    "                                p = prefix.p_blank_prev + symbol_prob\n",
    "\n",
    "                            elif prefix.symbol != symbol:\n",
    "                                p = prefix.score + symbol_prob\n",
    "\n",
    "                            new_prefix.add_p_non_blank(p)\n",
    "\n",
    "            prefixes.step()\n",
    "\n",
    "        prefixes.finalize()\n",
    "\n",
    "        return prefixes.best()\n",
    "\n",
    "    batch[\"lm_str\"] = decode(np.asarray(batch[\"lm_raw\"]))\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15588\n"
     ]
    }
   ],
   "source": [
    "print(len(res51_full_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "batch_size = 2000\n",
    "dataset_length = len(res51_full_log)\n",
    "\n",
    "for i in range(0, dataset_length, batch_size):\n",
    "    chunk = Dataset.from_dict(res51_full_log[i:i+batch_size])\n",
    "    chunk = chunk.map(infer_lm, fn_kwargs=dict(word_lm_scorer=word_lm_scorer, vocabulary=vocab), num_proc=6)\n",
    "    chunk.save_to_disk(\"lm_res51/full_full_chunks/chunk\" + str(i) + \"_\" + str(i+batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_res51/full_full_chunks\\chunk2000_4000\n",
      "lm_res51/full_full_chunks\\chunk4000_6000\n",
      "lm_res51/full_full_chunks\\chunk6000_8000\n",
      "lm_res51/full_full_chunks\\chunk8000_10000\n",
      "lm_res51/full_full_chunks\\chunk10000_12000\n",
      "lm_res51/full_full_chunks\\chunk12000_14000\n",
      "lm_res51/full_full_chunks\\chunk14000_16000\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "res51 = load_from_disk(\"lm_res51/full_full_chunks/chunk0_2000\")\n",
    "\n",
    "for file_name in glob.iglob(\"lm_res51/full_full_chunks/chunk*\"):\n",
    "    if(file_name ==\"lm_res51/full_full_chunks\\chunk0_2000\"):\n",
    "        i= 0\n",
    "        # do nothing\n",
    "    else:\n",
    "        print(file_name)\n",
    "        res_chunk = load_from_disk(file_name)\n",
    "        res51 = concatenate_datasets([res51, res_chunk])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15588"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res51.save_to_disk(\"lm_full_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lm_str</th>\n",
       "      <th>pred_str</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wago aus sieben bürgen die stadt</td>\n",
       "      <td>wagozchi aus sieben bürgen die stadt</td>\n",
       "      <td>rkczi aus siebenbürgen die stadt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im laufe der zeit wandelte sich der name zu de</td>\n",
       "      <td>im laufe der zeit wandelte sich der name zu ede</td>\n",
       "      <td>im laufe der zeit wandelte sich der name zu de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>balzer begann ihre sportliche karriere als sieben kämpferin</td>\n",
       "      <td>balte begann ihre sportliche karriere als siebenkämpferin</td>\n",
       "      <td>balta begann ihre sportliche karriere als siebenkämpferin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wir sind doch hier nicht eine f</td>\n",
       "      <td>wir sind doch hier nicht eine fh</td>\n",
       "      <td>wir sind hier doch nicht an der fh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sieben</td>\n",
       "      <td>sieben</td>\n",
       "      <td>sieben</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>es ist mit eis und glatte zum rechten warum sie daher besonders vorsichtig</td>\n",
       "      <td>es ist mit eis und glätte zum rechten warum sie daher besonders vorsichlih</td>\n",
       "      <td>es ist mit eis und glätte zu rechnen fahren sie daher besonders vorsichtig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wir sind zwillinge</td>\n",
       "      <td>wir sind zwi linge</td>\n",
       "      <td>wir sind zwillinge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>alle in frankreich geltenden gesetze wurden eingeführt</td>\n",
       "      <td>alle in frankreich geltenden gesetze wurden eingeführt</td>\n",
       "      <td>alle in frankreich geltenden gesetze wurden eingeführt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>was läuft heute abend im fernsehen</td>\n",
       "      <td>was läuft heute abend im fernsehen</td>\n",
       "      <td>was läuft heute abend im fernsehen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>er spielte unter anderem hamlet und mack bath</td>\n",
       "      <td>er spielte unter anderem humlet und mack bath</td>\n",
       "      <td>er spielte unter anderem hamlet und macbeth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(res51.remove_columns([\"speech\", \"sampling_rate\", \"lm_raw\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test WER: 0.148\n"
     ]
    }
   ],
   "source": [
    "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=res51[\"lm_str\"], references=res51[\"target_text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test WER: 0.171\n"
     ]
    }
   ],
   "source": [
    "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=res51[\"pred_str\"], references=res51[\"target_text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "results51_full = load_from_disk(\"results51_test\")\n",
    "results51_cut = load_from_disk(\"results51_cut\")\n",
    "results51_cut_log = load_from_disk(\"res51_cut_log\")\n",
    "results51_full_log = load_from_disk(\"res51_full_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Test WER: 0.147\n",
      "Cut Test WER: 0.148\n",
      "Cut Log Test WER: 0.148\n",
      "Full Log Test WER: 0.147\n"
     ]
    }
   ],
   "source": [
    "print(\"Full Test WER: {:.3f}\".format(wer_metric.compute(predictions=results51_full[\"pred_str\"], references=results51_full[\"target_text\"])))\n",
    "print(\"Cut Test WER: {:.3f}\".format(wer_metric.compute(predictions=results51_cut[\"pred_str\"], references=results51_cut[\"target_text\"])))\n",
    "print(\"Cut Log Test WER: {:.3f}\".format(wer_metric.compute(predictions=results51_cut_log[\"pred_str\"], references=results51_cut_log[\"target_text\"])))\n",
    "print(\"Full Log Test WER: {:.3f}\".format(wer_metric.compute(predictions=results51_full_log[\"pred_str\"], references=results51_full_log[\"target_text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "sieht euch bitte draußen die schuhe aus\n",
      "zieht euch bitte draußen die schuhe aus \n",
      "\n",
      "zieht euch bitte draußen die schuhe aus\n",
      "sieht euch bitte draußen die schuhe aus\n",
      "sieht euch bitte draußen die schuhe aus\n",
      "zieht euch bitte draußen die schuhe aus\n",
      "\n",
      "zieht euch bitte draußen die schuhe aus \n",
      "1\n",
      "es romi schwon geworden tet\n",
      "des komischerweise \n",
      "\n",
      "des komtikolnegabentert\n",
      "es romi schwon geworden tet\n",
      "es romi schwon geworden tet\n",
      "des komtikolnegabentert\n",
      "\n",
      "es kommt zum showdown in gstaad \n",
      "2\n",
      "ihre forterstrecken erschienen den modemagazin wie der wolg ab das basain var ricler\n",
      "ihre fotostrecken erschienen in modemagazin wie der volk hat das basra regler \n",
      "\n",
      "ihre fortestrecken erschienen mit molemagazine wie der wog at das basarwaryclar\n",
      "ihre forterstrecken erschienen den modemagazin wie der wolg ab das basain var ricler\n",
      "ihre forterstrecken erschienen den modemagazin wie der wolg ab das basain var ricler\n",
      "ihre fortestrecken erschienen mit molemagazine wie der wog at das basarwaryclar\n",
      "\n",
      "ihre fotostrecken erschienen in modemagazinen wie der vogue harpers bazaar und marie claire \n",
      "3\n",
      "velipe hat eine auch für monarchen ungewöhnlich lange titelliste\n",
      "felipe hat eine auch für monarchen ungewöhnlich lange titelliste \n",
      "\n",
      "verlibert eine auch für monachen ungewöhnlich lange titelliste\n",
      "velipe hat eine auch für monarchen ungewöhnlich lange titelliste\n",
      "velipe hat eine auch für monarchen ungewöhnlich lange titelliste\n",
      "verlibert eine auch für monachen ungewöhnlich lange titelliste\n",
      "\n",
      "felipe hat eine auch für monarchen ungewöhnlich lange titelliste \n",
      "4\n",
      "er wurde zu ehren des reichskanzlers otto von bismark errichtet\n",
      "er wurde zu ehren des reichskanzler otto von bismarck errichtet \n",
      "\n",
      "er wurde zu ehren des reichskanzlers otto von bismark errichtet\n",
      "er wurde zu ehren des reichskanzlers otto von bismark errichtet\n",
      "er wurde zu ehren des reichskanzlers otto von bismark errichtet\n",
      "er wurde zu ehren des reichskanzlers otto von bismark errichtet\n",
      "\n",
      "er wurde zu ehren des reichskanzlers otto von bismarck errichtet \n",
      "5\n",
      "was solls ich bin bereit\n",
      "was solls ich bin bereit \n",
      "\n",
      "was solls ich bin bereit\n",
      "was solls ich bin bereit\n",
      "was solls ich bin bereit\n",
      "was solls ich bin bereit\n",
      "\n",
      "was solls ich bin bereit \n",
      "6\n",
      "das internet besteht aus vielen computern die miteinander verbunden sind\n",
      "das internet besteht aus vielen computern die miteinander verbunden sind \n",
      "\n",
      "das internet besteht aus vielen computern die miteinander verbunden sind\n",
      "das internet besteht aus vielen computern die miteinander verbunden sind\n",
      "das internet besteht aus vielen computern die miteinander verbunden sind\n",
      "das internet besteht aus vielen computern die miteinander verbunden sind\n",
      "\n",
      "das internet besteht aus vielen computern die miteinander verbunden sind \n",
      "7\n",
      "der uranus ist der siebentelplanet in unserem sonnensystem\n",
      "der uranus ist der siebente planet in unserem sonnensystem \n",
      "\n",
      "der uranus ist eir siebente planet en u unsermsammensystem\n",
      "der uranus ist der siebentelplanet in unserem sonnensystem\n",
      "der uranus ist der siebentelplanet in unserem sonnensystem\n",
      "der uranus ist eir siebente planet en u unsermsammensystem\n",
      "\n",
      "der uranus ist der siebente planet in unserem sonnensystem \n",
      "8\n",
      "die wagen erhielten ein einheitliches erscheinungsbild in weiß mit rotem fensterband\n",
      "die wagen erhielten ein einheitliches erscheinungsbild in weiß mit rotem fensterband \n",
      "\n",
      "die wagen erhielten ein einheitliches erscheinungsbild in weis mit rotem fensterband\n",
      "die wagen erhielten ein einheitliches erscheinungsbild in weiß mit rotem fensterband\n",
      "die wagen erhielten ein einheitliches erscheinungsbild in weiß mit rotem fensterband\n",
      "die wagen erhielten ein einheitliches erscheinungsbild in weis mit rotem fensterband\n",
      "\n",
      "die wagen erhielten ein einheitliches erscheinungsbild in weiß mit rotem fensterband \n",
      "9\n",
      "sie war die cousine von karlmaria von weber\n",
      "sie war die cousine von karl maria von weber \n",
      "\n",
      "sie war die cousinefin karlmaria vin weber\n",
      "sie war die cousine von karlmaria von weber\n",
      "sie war die cousine von karlmaria von weber\n",
      "sie war die cousinefin karlmaria vin weber\n",
      "\n",
      "sie war die cousine von carl maria von weber \n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    print(res51[i][\"pred_str\"])\n",
    "    print(res51[i][\"lm_str\"])\n",
    "    print(\"\")\n",
    "    print(results51_full[i][\"pred_str\"])\n",
    "    print(results51_cut[i][\"pred_str\"])\n",
    "    print(results51_cut_log[i][\"pred_str\"])\n",
    "    print(results51_full_log[i][\"pred_str\"])\n",
    "    print(\"\")\n",
    "    print(results51_full_log[i][\"target_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
